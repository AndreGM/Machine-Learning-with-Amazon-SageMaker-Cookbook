{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e64ab6",
   "metadata": {},
   "source": [
    "# Training and Deploying a TensorFlow and Keras model with Amazon SageMaker Local Mode\n",
    "\n",
    "Performing training and deployment of a custom **TensorFlow** and **Keras** model with **SageMaker** is fairly straightforward. Step # 1 involves creating the entrypoint script where our custom neural network and training logic are defined and coded. Step # 2 involves using this script as an argument to the TensorFlow estimator from the **SageMaker Python SDK** to proceed with the training and deployment steps.\n",
    "\n",
    "In this recipe, we will focus on step # 2 and proceed with the training and deployment of our custom **TensorFlow** and **Keras** neural network model in SageMaker. If you are looking for step # 1, feel free to check the previous recipe `Preparing the entrypoint TensorFlow and Keras training script`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4885e81",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'sagemaker[local]' --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab522bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo service docker restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d05e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker rmi -f $(docker images -a -q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = 'sagemaker-cookbook-bucket'\n",
    "prefix = 'chapter03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cc5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3 = f\"s3://{s3_bucket}/{prefix}/synthetic/training_data.csv\" \n",
    "val_s3 = f\"s3://{s3_bucket}/{prefix}/synthetic/validation_data.csv\" \n",
    "s3_output_location = f\"s3://{s3_bucket}/{prefix}/output/tensorflow/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6abe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "    \n",
    "train_input = TrainingInput(train_s3, content_type=\"text/csv\")\n",
    "val_input = TrainingInput(val_s3, content_type=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.local import LocalSession\n",
    "\n",
    "sagemaker_session = LocalSession()\n",
    "sagemaker_session.config = {'local': {'local_code': True}}\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462f5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='tensorflow_script.py',\n",
    "                       output_path=s3_output_location,\n",
    "                       role=role,\n",
    "                       sesion=sagemaker_session,\n",
    "                       instance_count=1,\n",
    "                       instance_type='local',\n",
    "                       framework_version='2.1.0',\n",
    "                       py_version='py3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6461cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': train_input, 'validation': val_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba815662",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "  'instances': [[100], [200]]\n",
    "}\n",
    "result = predictor.predict(input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d97b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_s3 = f\"s3://{s3_bucket}/{prefix}/synthetic/all_data.csv\" \n",
    "!aws s3 cp {all_s3} tmp/all_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_data = pd.read_csv(\"tmp/all_data.csv\", header=None)\n",
    "x = all_data[[1]].values\n",
    "y = all_data[[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "\n",
    "line_x = arange(-5000, 5000, 10)\n",
    "line_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "  'instances': line_x.reshape(-1, 1)\n",
    "}\n",
    "result = predictor.predict(input)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "line_y = np.array(result['predictions']).flatten()\n",
    "line_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52828b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(line_x, line_y, 'r')\n",
    "pyplot.scatter(x,y,s=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b59a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705c298",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"130\" src=\"https://raw.githubusercontent.com/PacktPublishing/Amazon-SageMaker-Cookbook/master/Extra/cover-small-padded.png\"/>\n",
    "\n",
    "This notebook contains the code to help readers work through one of the recipes of the book [Machine Learning with Amazon SageMaker Cookbook: 80 proven recipes for data scientists and developers to perform ML experiments and deployments](https://www.amazon.com/Machine-Learning-Amazon-SageMaker-Cookbook/dp/1800567030)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
