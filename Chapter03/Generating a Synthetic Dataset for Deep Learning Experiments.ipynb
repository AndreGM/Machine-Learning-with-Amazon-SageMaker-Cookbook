{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35827f3",
   "metadata": {},
   "source": [
    "# Generating a Synthetic Dataset for Deep Learning Experiments\n",
    "\n",
    "Synthetic data generation is the process of programmatically generating artificial data with the purpose of helping data scientists and machine learning engineers test different algorithms and perform machine learning experiments without using real collected data. As we will work with neural networks and deep learning frameworks, we will need an acceptably large dataset. The dataset we have in Chapter 1 has only 20 records and will definitely not be a good fit for the recipes in this chapters. In this recipe, we will generate training, validation, and test dummy data using a custom synthetic data generator and store these datasets to **Amazon S3**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7f66b",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c859e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c70543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula(x):\n",
    "    if x >= -2000:\n",
    "        return x\n",
    "    else:\n",
    "        return -x - 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f4f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=1000, \n",
    "                            start=-5000, \n",
    "                            end=5000):\n",
    "    np.random.seed(42)\n",
    "    x = np.random.randint(low=start, \n",
    "                          high=end, \n",
    "                          size=(n_samples,)).astype(int)\n",
    "    \n",
    "    y = np.vectorize(formula)(x) + \\\n",
    "        np.random.normal(150, 150, n_samples) \n",
    "    \n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3327c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_synthetic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58051569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ec612",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.rcParams[\"figure.figsize\"] = (10,8)\n",
    "pyplot.scatter(X,y,s=1)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9176c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4308e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660452c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all_data = pd.DataFrame({ 'y': y, 'x': X})\n",
    "df_all_data.to_csv('tmp/all_data.csv', header=False, index=False)\n",
    "\n",
    "df_training_data = pd.DataFrame({ 'y': y_train, 'x': X_train})\n",
    "df_training_data.to_csv('tmp/training_data.csv', header=False, index=False)\n",
    "\n",
    "df_validation_data = pd.DataFrame({ 'y': y_validation, 'x': X_validation})\n",
    "df_validation_data.to_csv('tmp/validation_data.csv', header=False, index=False)\n",
    "\n",
    "df_test_data = pd.DataFrame({ 'y': y_test, 'x': X_test})\n",
    "df_test_data.to_csv('tmp/test_data.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"sagemaker-cookbook-bucket\"\n",
    "prefix = \"chapter03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba53c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp tmp/training_data.csv \\\n",
    "s3://{s3_bucket}/{prefix}/synthetic/all_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp tmp/training_data.csv \\\n",
    "s3://{s3_bucket}/{prefix}/synthetic/training_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc7ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp tmp/validation_data.csv \\\n",
    "s3://{s3_bucket}/{prefix}/synthetic/validation_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp tmp/test_data.csv \\\n",
    "s3://{s3_bucket}/{prefix}/synthetic/test_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff61987",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"130\" src=\"https://raw.githubusercontent.com/PacktPublishing/Amazon-SageMaker-Cookbook/master/Extra/cover-small-padded.png\"/>\n",
    "\n",
    "This notebook contains the code to help readers work through one of the recipes of the book [Machine Learning with Amazon SageMaker Cookbook: 80 proven recipes for data scientists and developers to perform ML experiments and deployments](https://www.amazon.com/Machine-Learning-Amazon-SageMaker-Cookbook/dp/1800567030)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
