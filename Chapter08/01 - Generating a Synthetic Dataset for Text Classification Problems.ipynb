{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a Synthetic Dataset for Text Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"130\" src=\"https://raw.githubusercontent.com/PacktPublishing/Amazon-SageMaker-Cookbook/master/Extra/cover-small-padded.png\"/>\n",
    "\n",
    "This notebook contains the code to help readers work through one of the recipes of the book [Machine Learning with Amazon SageMaker Cookbook: 80 proven recipes for data scientists and developers to perform ML experiments and deployments](https://www.amazon.com/Machine-Learning-Amazon-SageMaker-Cookbook/dp/1800567030)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "faker = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_custom_list = [\n",
    "    'this is good', \n",
    "    'i like it', \n",
    "    'very delicious', \n",
    "    'i would recommend this to my friends',\n",
    "    'food in the restaurant',\n",
    "    'spaghetti chicken soup',\n",
    "    'dinner time',\n",
    "    'tastes good',\n",
    "    'donut',\n",
    "    'very good',\n",
    "    'impressive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positive_sentences():\n",
    "    return faker.sentence(\n",
    "        ext_word_list=positive_custom_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_custom_list = [\n",
    "    'this is bad', \n",
    "    'i hate it', \n",
    "    'there are better restaurants out there', \n",
    "    'i will not recommend this to my friends',\n",
    "    'food in the restaurant',\n",
    "    'spaghetti chicken soup',\n",
    "    'dinner time',\n",
    "    'tastes bad',\n",
    "    'donut',\n",
    "    'very bad',\n",
    "    'not impressive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_sentences():\n",
    "    return faker.sentence(\n",
    "        ext_word_list=negative_custom_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sentences = []\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    item = generate_positive_sentences()\n",
    "    item = item.replace(\".\",\"\")\n",
    "    positive_sentences.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "positive_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sentences = []\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    item = generate_negative_sentences()\n",
    "    item = item.replace(\".\",\"\")\n",
    "    negative_sentences.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "positive_df = pd.DataFrame(\n",
    "    positive_sentences, \n",
    "    columns=['text']\n",
    ")\n",
    "\n",
    "positive_df.insert(\n",
    "    0, \n",
    "    \"label\", \n",
    "    \"__label__positive\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df = pd.DataFrame(\n",
    "    negative_sentences, \n",
    "    columns=['text']\n",
    ")\n",
    "negative_df.insert(\n",
    "    0, \n",
    "    \"label\", \n",
    "    \"__label__negative\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat(\n",
    "    [positive_df, negative_df], \n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_val_df, test_df = train_test_split(\n",
    "    all_df, \n",
    "    test_size=0.2\n",
    ") \n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, \n",
    "    test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir tmp \n",
    "train_df.to_csv(\n",
    "    \"tmp/synthetic.train.txt\", \n",
    "    header=False, \n",
    "    index=False, \n",
    "    sep=\" \", \n",
    "    quotechar=\" \"\n",
    ")\n",
    "val_df.to_csv(\n",
    "    \"tmp/synthetic.validation.txt\", \n",
    "    header=False, \n",
    "    index=False, \n",
    "    sep=\" \", \n",
    "    quotechar=\" \"\n",
    ") \n",
    "test_df.to_csv(\n",
    "    \"tmp/synthetic.test.txt\", \n",
    "    header=False, \n",
    "    index=False, \n",
    "    sep=\" \", \n",
    "    quotechar=\" \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head tmp/synthetic.train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"sagemaker-cookbook-bucket\"\n",
    "prefix = \"chapter08\"\n",
    "!aws s3 cp tmp/synthetic.train.txt s3://{s3_bucket}/{prefix}/input/synthetic.train.txt \n",
    "!aws s3 cp tmp/synthetic.validation.txt s3://{s3_bucket}/{prefix}/input/synthetic.validation.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store test_df\n",
    "%store s3_bucket\n",
    "%store prefix"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
